<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Biometrics Grid</title>
    <!-- Load TensorFlow.js -->
    <script defer src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <!-- Load face-api.js -->
    <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>
    <style>
        body {
            margin: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            background: black;
            color: white;
        }
        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
        }
        button {
            margin-top: 500px;
            background: darkslategrey;
            color: white;
            border: none;
            padding: 10px 20px;
            cursor: pointer;
            font-size: 16px;
            position: relative;
            z-index: 1;
        }
    </style>
</head>
<body>
    <video id="video" width="640" height="480" autoplay muted></video>
    <canvas id="overlay" width="640" height="480"></canvas>
    <button id="snap">I agree</button>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('overlay');
        const ctx = canvas.getContext('2d');
        const snap = document.getElementById('snap');

        async function setupCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
                video.srcObject = stream;
                return new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        resolve();
                    };
                });
            } catch (err) {
                console.error('Error accessing webcam:', err);
            }
        }

        async function loadModels() {
            const modelUrl = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/';
            await faceapi.nets.tinyFaceDetector.loadFromUri(modelUrl);
            await faceapi.nets.faceLandmark68Net.loadFromUri(modelUrl);
        }

        async function detectFace() {
            const options = new faceapi.TinyFaceDetectorOptions();
            const detections = await faceapi.detectAllFaces(video, options).withFaceLandmarks();

            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            if (detections.length > 0) {
                detections.forEach((detection) => {
                    // Draw face box
                    const box = detection.detection.box;
                    ctx.strokeStyle = 'red';
                    ctx.lineWidth = 2;
                    ctx.strokeRect(box.x, box.y, box.width, box.height);

                    // Draw face landmarks grid
                    detection.landmarks.positions.forEach(({ x, y }) => {
                        ctx.fillStyle = 'blue';
                        ctx.beginPath();
                        ctx.arc(x, y, 2, 0, 2 * Math.PI);
                        ctx.fill();
                    });
                });
            }

            requestAnimationFrame(detectFace);
        }

        snap.addEventListener('click', () => {
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        });

        async function main() {
            await setupCamera();
            await loadModels();
            detectFace();
        }

        main();
    </script>
</body>
</html>
